{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Rules and their applications\n",
    "### Part I. Implementation\n",
    "\n",
    "Here I present my implementation of the Rule Learner algorithm. While it is probably possible to further improve performance, I could not find a way to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PRISM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. First: two classes\n",
    "\n",
    "### `Condition` class with printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition:\n",
    "    def __init__(self, attribute, value, true_false = None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.true_false = true_false\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.true_false is None:\n",
    "            return \"{}={}\".format(self.attribute, self.value)\n",
    "        else:\n",
    "            if self.true_false:\n",
    "                return \"{}>={}\".format(self.attribute, self.value)\n",
    "            else:\n",
    "                return \"{}<{}\".format(self.attribute, self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Rule` class with printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, class_label):\n",
    "        self.conditions = []  # list of conditions\n",
    "        self.class_label = class_label  # rule class\n",
    "\n",
    "    def add_condition(self, condition):\n",
    "        self.conditions.append(condition)\n",
    "\n",
    "    def set_params(self, accuracy, coverage):\n",
    "        self.accuracy = accuracy\n",
    "        self.coverage = coverage\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"If {} then {}. Coverage:{}, accuracy: {}\".format(self.conditions, self.class_label,\n",
    "                                                                 self.coverage, self.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Constructing filters\n",
    "\n",
    "Given a condition or a list of conditions, these functions construct a filtering condition to be applied to the current pandas data frame. Both functions return a string. The string then can be converted into a boolean condition using `eval`. This method was proposed by Colin Pinney. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_filter(condition, dataset_name):\n",
    "    if condition is None:\n",
    "        return \"\"\n",
    "    if condition.true_false is None:  # categorical attribute\n",
    "        return '('+dataset_name+'[\"' + condition.attribute + '\"]' + \"==\" + '\"' + condition.value + '\")'\n",
    "    if condition.true_false: # >= numeric value\n",
    "        return '('+dataset_name+'[\"' + condition.attribute + '\"]' + \">=\" + str(condition.value) + \")\"\n",
    "    return '('+dataset_name+'[\"' + condition.attribute + '\"]' + \"<\" + str(condition.value) + \")\"\n",
    "\n",
    "\n",
    "def condition_list_filter(condition_list, dataset_name):\n",
    "    result = \"\"\n",
    "\n",
    "    for cond in condition_list:\n",
    "        result += condition_filter(cond, dataset_name) + \" & \"\n",
    "\n",
    "    result += \"True\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Best condition\n",
    "\n",
    "This function tries all different combinations of attribute-values and seeks the combination that would give the best accuracy of the rule, where accuracy is defined as number of records which have both condition and class over all records with the current condition.\n",
    "\n",
    "The function takes as a parameter a current subset of data, and performs only reading operations on this subset - tocount the accuracy. It also evaluates a coverage of the rule which is defined as a total number of records which satisfy current condition.\n",
    "\n",
    "The function returns an object representing the condition with best accuracy. If the coverage falls below the specified threshold, the function returns None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_condition(columns, current_subset, prev_conditions, \n",
    "                       class_label, min_coverage=30, prev_best_accuracy=0.0):\n",
    "    \n",
    "    # we do not check the same column that was already used to generate this subset\n",
    "    used_attributes = [x.attribute for x in prev_conditions]\n",
    "    \n",
    "    best_accuracy = prev_best_accuracy\n",
    "    best_coverage = None\n",
    "    best_col = None\n",
    "    best_val = None\n",
    "    best_true_false = None\n",
    "\n",
    "    # we iterate over all attributes except the class - which is in the last column\n",
    "    for col in columns[:-1]:\n",
    "        # we do not use the same column in one rule\n",
    "        if col in used_attributes:\n",
    "            continue\n",
    "\n",
    "        # Extract unique values from the column\n",
    "        unique_vals = current_subset[col].unique().tolist()\n",
    "\n",
    "        # Consider each unique value in turn\n",
    "        # The treatment is different for numeric and categorical attributes\n",
    "        for val in unique_vals:\n",
    "            if isinstance(val, int) or isinstance(val, float):\n",
    "                # Here we construct 2 conditions:\n",
    "                # if actual value >= val or if actual value < val\n",
    "\n",
    "                # First if actual value >= val                \n",
    "                new_condition = Condition(col, val, True)\n",
    "\n",
    "                # create a filtering condition\n",
    "                filter = condition_filter(new_condition, \"current_subset\")\n",
    "\n",
    "                # total covered by current condition\n",
    "                total_covered = len(current_subset[eval(filter)])\n",
    "                if total_covered >= min_coverage:\n",
    "                    # total with this condition and a given class\n",
    "                    total_correct = len(current_subset[(current_subset[columns[-1]] == class_label) & eval(filter)])\n",
    "\n",
    "                    acc = total_correct/total_covered\n",
    "                    if acc > best_accuracy or (acc == best_accuracy and\n",
    "                                               (best_coverage is None or total_covered > best_coverage)):\n",
    "                        best_accuracy = acc\n",
    "                        best_coverage = total_covered\n",
    "                        best_col = col\n",
    "                        best_val = val\n",
    "                        best_true_false = True\n",
    "\n",
    "                # now repeat the same for the case - if actual value < val                \n",
    "                new_condition = Condition(col, val, False)\n",
    "\n",
    "                # create a filtering condition\n",
    "                filter = condition_filter(new_condition, \"current_subset\")\n",
    "\n",
    "                # total covered by current condition\n",
    "                total_covered = len(current_subset[eval(filter)])\n",
    "                if total_covered >= min_coverage:\n",
    "                    # total with this condition and a given class\n",
    "                    total_correct = len(current_subset[(current_subset[columns[-1]] == class_label) & eval(filter)])\n",
    "\n",
    "                    acc = total_correct / total_covered\n",
    "                    if acc > best_accuracy or (acc == best_accuracy and\n",
    "                                               (best_coverage is None or total_covered > best_coverage)):\n",
    "                        best_accuracy = acc\n",
    "                        best_coverage = total_covered\n",
    "                        best_col = col\n",
    "                        best_val = val\n",
    "                        best_true_false = False\n",
    "\n",
    "            else: # categorical attribute\n",
    "                # For categorical attributes - this is just single condition if actual value == val\n",
    "                new_condition = Condition(col, val)\n",
    "\n",
    "                # create a filtering condition\n",
    "                filter = condition_filter(new_condition, \"current_subset\")\n",
    "\n",
    "                # total covered by current condition\n",
    "                total_covered = len(current_subset[eval(filter)])\n",
    "\n",
    "                if total_covered >= min_coverage:\n",
    "                    # total with this condition and a given class\n",
    "                    total_correct = len(current_subset[(current_subset[columns[-1]] == class_label) & eval(filter)])\n",
    "\n",
    "                    acc = total_correct / total_covered\n",
    "                    if acc > best_accuracy or (acc == best_accuracy and\n",
    "                                               (best_coverage is None or total_covered > best_coverage)):\n",
    "                        best_accuracy = acc\n",
    "                        best_coverage = total_covered\n",
    "                        best_col = col\n",
    "                        best_val = val\n",
    "                        best_true_false = None\n",
    "\n",
    "    if best_col is None:\n",
    "        return None\n",
    "    return Condition(best_col,best_val, best_true_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Learn one rule\n",
    "\n",
    "Here we try to learn a single rule. We start with a single best condition, and try adding more conditions to improve the accuracy as long as the coverage does not fall below the specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_one_rule(columns, current_data, class_label,\n",
    "                   min_coverage=30):\n",
    "\n",
    "    covered_subset = None\n",
    "    \n",
    "    # start with creating a new Rule with a single best condition\n",
    "    current_rule = Rule(class_label)\n",
    "    best_condition = get_best_condition(columns, current_data, [], class_label, min_coverage)\n",
    "\n",
    "    if best_condition is None:\n",
    "        return None\n",
    "\n",
    "    current_rule.add_condition(best_condition)\n",
    "    \n",
    "    # create a filtering condition\n",
    "    filter = condition_filter (best_condition,\"current_data\")\n",
    "\n",
    "    # total covered by current condition\n",
    "    total_covered = len(current_data[eval(filter)])\n",
    "    \n",
    "    if total_covered < min_coverage:\n",
    "        return None\n",
    "\n",
    "    # total with this condition and a given class\n",
    "    total_correct = len(current_data[(current_data[columns[-1]] == class_label) & eval(filter)])\n",
    "\n",
    "    current_accuracy = total_correct / total_covered\n",
    "    current_rule.set_params(current_accuracy, total_covered )  \n",
    "\n",
    "    if current_accuracy == 1.0:\n",
    "        return current_rule\n",
    "\n",
    "    # leave only a subset where the best condition holds\n",
    "    covered_subset = current_data[eval(filter)]\n",
    "\n",
    "    # repeatedly try to improve Rule's accuracy as long as coverage remains sufficient\n",
    "    while True:\n",
    "        best_condition = get_best_condition(columns, covered_subset, current_rule.conditions,\n",
    "                                            class_label, min_coverage, current_accuracy)\n",
    "\n",
    "        if best_condition is None: \n",
    "            return current_rule\n",
    "\n",
    "        # create an additional filtering condition on the current subset\n",
    "        filter = condition_filter(best_condition, \"covered_subset\")\n",
    "\n",
    "        # total covered by current condition\n",
    "        total_covered = len(covered_subset[eval(filter)])\n",
    "\n",
    "        if total_covered < min_coverage:\n",
    "            return current_rule  # we could not improve previous rule\n",
    "\n",
    "        # total with this condition and a given class\n",
    "        total_correct = len(covered_subset[(covered_subset[columns[-1]] == class_label) & eval(filter)])\n",
    "\n",
    "        new_accuracy = total_correct / total_covered\n",
    "\n",
    "        current_rule.add_condition(best_condition)\n",
    "        current_rule.set_params(new_accuracy, total_covered)\n",
    "        current_accuracy = new_accuracy\n",
    "\n",
    "        if new_accuracy == 1: # stop improving\n",
    "            return current_rule\n",
    "\n",
    "        # update subset to continue working with\n",
    "        covered_subset = covered_subset[eval(filter)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Learn all rules\n",
    "\n",
    "This implementation follows the logic of the original PRISM algorithm. It processes each class in turn. \n",
    "Because high-accuracy rules generated by the algorithm are disjoint with respect to the class label, this is not a problem when we are just interested in dicovering some pieces of knowledge - not in constructing the classification table.\n",
    "For the Decision Table the order in which the rules are discovered matters, and we should process all classes at the same time, as shown in the lecture examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_rules(columns, data, classes=None,\n",
    "                min_coverage=30, min_accuracy=0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "\n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "\n",
    "    # one class label at a time\n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) >= min_coverage and not done:\n",
    "            # Learn a rule with a single condition\n",
    "            rule = learn_one_rule(columns, current_data, class_label, min_coverage)\n",
    "\n",
    "            # The best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with coverage above threshold\n",
    "            # We check if it passes accuracy threshold\n",
    "            if rule.accuracy >= min_accuracy:\n",
    "                rules.append(rule)\n",
    "                             \n",
    "                # create a filtering condition\n",
    "                filter = condition_list_filter(rule.conditions,\"current_data\")\n",
    "                \n",
    "                # drop all the rows where all rule conditions hold\n",
    "                current_data = current_data.drop(current_data[eval(filter)].index)\n",
    "            else:\n",
    "                done = True\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Correctness test\n",
    "\n",
    "We will test the algorithm on a small Contact Lenses dataset from the original paper. \n",
    "\n",
    "The dataset was downloaded from [here](https://archive.ics.uci.edu/ml/datasets/Lenses). The CSV version is included in this repository.\n",
    "\n",
    "**Attribute Information**:\n",
    "\n",
    "3 Classes:\n",
    "- __1__ : the patient should be fitted with __hard__ contact lenses,\n",
    "- __2__ : the patient should be fitted with __soft__ contact lenses,\n",
    "- __3__ : the patient should __not__ be fitted with contact lenses.\n",
    "\n",
    "\n",
    "Attributes:\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "2. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "3. astigmatic:     (1) no, (2) yes\n",
    "4. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Presbyopia is physiological insufficiency of accommodation associated with the aging of the eye that results in progressively worsening ability to focus clearly on close objects. So \"age=presbiopic\" means old.\n",
    "\n",
    "Hypermetropia: far-sightedness, also known as long-sightedness - cannot see close.\n",
    "Myopia: nearsightedness - cannot see at distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'spectacles', 'astigmatism', 'tear production rate',\n",
       "       'lenses type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_file = \"contact_lenses.csv\"\n",
    "data = pd.read_csv(data_file, index_col=['id'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace numbers with actual values - for clarity of presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "conditions = [ data['lenses type'].eq(1), data['lenses type'].eq(2), data['lenses type'].eq(3)]\n",
    "choices = [\"hard\",\"soft\",\"none\"]\n",
    "\n",
    "data['lenses type'] = np.select(conditions, choices)\n",
    "\n",
    "# age groups\n",
    "conditions = [ data['age'].eq(1), data['age'].eq(2), data['age'].eq(3)]\n",
    "choices = [\"young\",\"medium\",\"old\"]\n",
    "\n",
    "data['age'] = np.select(conditions, choices)\n",
    "\n",
    "# spectacles\n",
    "conditions = [ data['spectacles'].eq(1), data['spectacles'].eq(2)]\n",
    "choices = [\"nearsighted\",\"farsighted\"]\n",
    "\n",
    "data['spectacles'] = np.select(conditions, choices)\n",
    "\n",
    "# astigmatism\n",
    "conditions = [ data['astigmatism'].eq(1), data['astigmatism'].eq(2)]\n",
    "choices = [\"no\",\"yes\"]\n",
    "\n",
    "data['astigmatism'] = np.select(conditions, choices)\n",
    "\n",
    "# tear production rate\n",
    "conditions = [ data['tear production rate'].eq(1), data['tear production rate'].eq(2)]\n",
    "choices = [\"reduced\",\"normal\"]\n",
    "\n",
    "data['tear production rate'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the algorithm next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = data.columns.to_numpy().tolist()\n",
    "rules = learn_rules(column_list, data, None, 1, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print all the rules in the order they were discovered. Note that first all the rules for class \"None\" were discovered, then for class \"Soft\", and finally for class \"Hard\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
      "If [age=old, tear production rate=normal, spectacles=nearsighted, astigmatism=no] then none. Coverage:1, accuracy: 1.0\n",
      "If [spectacles=farsighted, astigmatism=yes, age=medium] then none. Coverage:1, accuracy: 1.0\n",
      "If [age=old, spectacles=farsighted, astigmatism=yes] then none. Coverage:1, accuracy: 1.0\n",
      "If [astigmatism=no] then soft. Coverage:5, accuracy: 1.0\n",
      "If [astigmatism=yes] then hard. Coverage:4, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These rules precisely correspond to the rules computed by hand according to the algorithms's logic. The full step-by-step example is in [this file](https://docs.google.com/spreadsheets/d/1dw4X_veScVo0x1AS9wHTI9vxTfoemKoj/edit?usp=sharing&ouid=106298942908841514891&rtpof=true&sd=true)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want however to see rules sorted by accuracy, and for the same accuracy - sorted by coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
      "If [astigmatism=no] then soft. Coverage:5, accuracy: 1.0\n",
      "If [astigmatism=yes] then hard. Coverage:4, accuracy: 1.0\n",
      "If [age=old, tear production rate=normal, spectacles=nearsighted, astigmatism=no] then none. Coverage:1, accuracy: 1.0\n",
      "If [spectacles=farsighted, astigmatism=yes, age=medium] then none. Coverage:1, accuracy: 1.0\n",
      "If [age=old, spectacles=farsighted, astigmatism=yes] then none. Coverage:1, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "\n",
    "# sort rules by accuracy descending\n",
    "rules.sort(key=attrgetter('accuracy', 'coverage'), reverse=True)\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we want to see what rules would be discovered if the best condition is determined using all the classes. \n",
    "The modified code is in [rule_learner_both_classes.py](rule_learner_both_classes.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rule_learner_both_classes as rlbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = rlbc.learn_rules(column_list, data, None, 1, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
      "If [astigmatism=no, spectacles=farsighted] then soft. Coverage:3, accuracy: 1.0\n",
      "If [astigmatism=yes, spectacles=nearsighted] then hard. Coverage:3, accuracy: 1.0\n",
      "If [age=old] then none. Coverage:2, accuracy: 1.0\n",
      "If [spectacles=nearsighted] then soft. Coverage:2, accuracy: 1.0\n",
      "If [age=medium] then none. Coverage:1, accuracy: 1.0\n",
      "If [age=young] then hard. Coverage:1, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "\n",
    "# sort rules by accuracy descending\n",
    "rules.sort(key=attrgetter('accuracy', 'coverage'), reverse=True)\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also precisely corresponds to the step-by-step example. So it seems that our implementation is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2022 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
